{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're going to play with very simple layer ANNs. Even with just one layer we'll be able to do some fun stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our activation function, just a simple sigmoidal curve called the logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_func(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the logistic function by plotting in in the range of -10 to 10 using this handy built-in numpy function *linspace*. This function takes the lower bound, the upper bound, and the number of values, and returns a *linearly spaced* vector including the lower and upper bounds. **Neat!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.          -8.94736842  -7.89473684  -6.84210526  -5.78947368\n",
      "  -4.73684211  -3.68421053  -2.63157895  -1.57894737  -0.52631579\n",
      "   0.52631579   1.57894737   2.63157895   3.68421053   4.73684211\n",
      "   5.78947368   6.84210526   7.89473684   8.94736842  10.        ]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-10, 10,20)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now plot it!\n",
    "pyplot.plot(x, logistic_func(x))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to make a simple network that generates the following truth table\n",
    "\n",
    "| Input 1 | Output |\n",
    "|---------|--------|\n",
    "| 0       | 0      |\n",
    "| 1       | 1      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933071490757153\n"
     ]
    }
   ],
   "source": [
    "# Since we're only using one value, our input\n",
    "# is a single value\n",
    "input_vector = np.array([1])\n",
    "input_weights = np.array([5])\n",
    "\n",
    "# because we're using numpy arrays, when we do multiplication\n",
    "# it will automatically perform it element-by-element\n",
    "input_x_weights = input_vector * input_weights\n",
    "neuron_sum = sum(input_x_weights)\n",
    "\n",
    "# Now apply our activation function to the \n",
    "# sum of the inputs*weights vector\n",
    "activation = logistic_func(neuron_sum)\n",
    "\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Since we're only using one value, our input\n",
    "# is a single value\n",
    "input_vector = np.array([0])\n",
    "input_weights = np.array([5])\n",
    "\n",
    "# because we're using numpy arrays, when we do multiplication\n",
    "# it will automatically perform it element-by-element\n",
    "input_x_weights = input_vector * input_weights\n",
    "neuron_sum = sum(input_x_weights)\n",
    "activation = logistic_func(neuron_sum)\n",
    "\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm, we're going to have a hard time multipling 0 by something to get a lower value...\n",
    "To fix this problem, we use something called a **bias node**. Basically, we give the neural network a constant value to use for situations exactly like this. This is typically set at 1, though -1 is also a common choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04742587317756678\n"
     ]
    }
   ],
   "source": [
    "# Now we're passing in a bias node with value set to 1\n",
    "# so we'll also have to give it's synapse a weight!\n",
    "input_vector = np.array([0, 1])\n",
    "\n",
    "# I just picked a few big values that will pull the \n",
    "# logistic function close to either 0 or 1 depending on\n",
    "# the value of the input. \n",
    "input_weights = np.array([6, -3])\n",
    "\n",
    "# because we're using numpy arrays, when we do multiplication\n",
    "# it will automatically perform it element-by-element\n",
    "input_x_weights = input_vector * input_weights\n",
    "neuron_sum = sum(input_x_weights)\n",
    "activation = logistic_func(neuron_sum)\n",
    "\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can shorten this a lot using some nice numpy built in functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04742587317756678\n"
     ]
    }
   ],
   "source": [
    "input_vector = np.array([0, 1])\n",
    "input_weights = np.array([6, -3])\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\n",
    "# numpy's dot function computes the inner product \n",
    "# e.g., [a,b].[c,d] = [a*c + b*d]\n",
    "activation = logistic_func(np.dot(input_vector, input_weights))\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Try your hand at choosing weights for a network that can compute this function\n",
    "\n",
    "| Input 1 | Output |\n",
    "|---------|--------|\n",
    "| 0       | 1      |\n",
    "| 1       | 0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Let's make it a bit more complex and add a second input!\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "| 0       | 0       | 0      |\n",
    "| 0       | 1       | 1      |\n",
    "| 1       | 0       | 1      |\n",
    "| 1       | 1       | 1      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You should make sure your weights handle all the possible binary inputs we can give this function -- like the following input vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = np.array([0, 0, 1])\n",
    "input_vector = np.array([0, 1, 1])\n",
    "input_vector = np.array([1, 0, 1])\n",
    "input_vector = np.array([1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What would you have to do if we wanted to have more than one output?\n",
    "Let's try to replicate the following truth table (i.e., mirror the bits)\n",
    "\n",
    "| Input 1 | Input 2 | Output 1 | Output 2 |\n",
    "|---------|---------|----------|----------|\n",
    "| 0       | 0       | 0        | 0        |\n",
    "| 0       | 1       | 1        | 0        |\n",
    "| 1       | 0       | 0        | 1        |\n",
    "| 1       | 1       | 1        | 1        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Because now each input node has more than one output node to connect to, we'll need more weights. \n",
    "\n",
    "#### We can store these weights as a matrix with 3 rows (one for each input plus the bias) and 2 columsn (one for each output). Thus, each value is a weight from the row's input node to the column's output node. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.881  0.881]\n"
     ]
    }
   ],
   "source": [
    "input_vector = np.array([1, 0, 1])\n",
    "\n",
    "#TODO: You'll have to change these weights! \n",
    "input_weights = np.array( [[1, 1],\n",
    "                           [1, 1],\n",
    "                           [1, 1]])\n",
    "\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\n",
    "# we get to take advantage of more numpy fancyness here,\n",
    "# when np.dot is given a matrix, it performs matrix multiplication!\n",
    "activation = logistic_func(np.dot(input_vector, input_weights))\n",
    "print(np.round(activation, decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You'll want to check all the possible combinations of 2-bit inputs again, like you did in Question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. If you're feeling brave, try your hand at this one.\n",
    "Hint: It's not as simple as it looks... You'll need more **layers** for this one!\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "| 0       | 0       | 0      |\n",
    "| 0       | 1       | 1      |\n",
    "| 1       | 0       | 1      |\n",
    "| 1       | 1       | 0      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
